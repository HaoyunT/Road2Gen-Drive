import os
import numpy as np
from metadrive import MetaDriveEnv
from stable_baselines3 import PPO

def evaluate():
    # 1. é…ç½®ç¯å¢ƒ
    # ä½ å½“å‰ RL æ˜¯åœ¨å›ºå®šåŒå›¾ (seed=42, num_scenarios=1) è®­ç»ƒçš„ã€‚
    # å› æ­¤é»˜è®¤å…ˆåšåŒå›¾è¯„ä¼°ï¼Œå†æŒ‰éœ€åˆ‡åˆ°æ³›åŒ–è¯„ä¼°ã€‚
    eval_mode = "same_map"  # å¯é€‰: "same_map" | "generalization"

    if eval_mode == "same_map":
        config = {
            "use_render": True,
            "traffic_density": 0.12,
            "map": "SCO",
            "manual_control": False,
            "num_scenarios": 1,
            "start_seed": 42,
            "window_size": (1200, 900),
        }
    else:
        config = {
            "use_render": True,
            "traffic_density": 0.12,
            "map": "SCO",
            "manual_control": False,
            "num_scenarios": 30,
            "start_seed": 5000,
            "window_size": (1200, 900),
        }

    # è¯„ä¼°é˜¶æ®µåŠ¨ä½œå¹³æ»‘ï¼ˆEMAï¼‰
    # é»˜è®¤å…³é—­ï¼Œä¿æŒä¸è®­ç»ƒç­–ç•¥ä¸€è‡´
    use_action_smoothing = False
    action_smoothing_alpha = 0.35
    
    print(f"æ­£åœ¨åˆå§‹åŒ–æ¼”ç¤ºç¯å¢ƒ... (mode={eval_mode})")
    env = MetaDriveEnv(config)
    
    # 2. åŠ è½½æ¨¡å‹
    # ç®€æ´ IL+RL æµç¨‹é»˜è®¤è¯„ä¼° RL æœ€ç»ˆæ¨¡å‹
    # å¯é€‰: "final" | "best" | "auto" | "bc"
    model_select = "bc"

    # auto: best -> final -> bc
    # final: final -> best -> bc
    # best: best -> final -> bc
    # bc: bc -> final -> best
    best_model_path = "checkpoints/best_model"
    rl_model_path = "checkpoints/rl_final_model"
    bc_model_path = "checkpoints/bc_policy"
    
    model = None
    
    if model_select == "best":
        candidate_paths = [best_model_path, rl_model_path, bc_model_path]
    elif model_select == "final":
        candidate_paths = [rl_model_path, best_model_path, bc_model_path]
    elif model_select == "bc":
        candidate_paths = [bc_model_path, rl_model_path, best_model_path]
    else:
        candidate_paths = [best_model_path, rl_model_path, bc_model_path]

    for candidate in candidate_paths:
        if os.path.exists(candidate + ".zip"):
            tag = "RL æœ€ä½³æ¨¡å‹" if candidate == best_model_path else (
                "RL å¾®è°ƒæœ€ç»ˆæ¨¡å‹" if candidate == rl_model_path else "BC æ¨¡å‹"
            )
            print(f"âœ… åŠ è½½ {tag}: {candidate}")
            model = PPO.load(candidate)
            break

    if model is None:
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶ï¼è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ã€‚")
        env.close()
        return
    
    obs, info = env.reset()
    
    print("="*60)
    print("ğŸ¤– è‡ªåŠ¨é©¾é©¶æ¼”ç¤ºå¼€å§‹ï¼")
    print("æŒ‰ [ESC] é€€å‡ºç¨‹åº")
    print("="*60)

    episode_count = 0
    prev_action = None
    try:
        # è·‘ 5000 æ­¥
        for i in range(5000):
            # deterministic=True å¾ˆå…³é”®
            # è®­ç»ƒæ—¶æˆ‘ä»¬éœ€è¦éšæœºæ€§(std)æ¥æ¢ç´¢ï¼Œæ¼”ç¤ºæ—¶æˆ‘ä»¬è¦æœ€ç¨³çš„ç­–ç•¥(å‡å€¼)
            action, _ = model.predict(obs, deterministic=True)

            if use_action_smoothing:
                action = np.asarray(action, dtype=np.float32)
                if prev_action is None:
                    smooth_action = action
                else:
                    smooth_action = (
                        action_smoothing_alpha * action
                        + (1.0 - action_smoothing_alpha) * prev_action
                    )
                prev_action = smooth_action
                action_to_env = smooth_action
            else:
                action_to_env = action

            obs, reward, done, truncated, info = env.step(action_to_env)
            
            # åœ¨ç”»é¢å·¦ä¸Šè§’æ˜¾ç¤ºçŠ¶æ€
            env.render(text={
                "Mode": "AI Auto-Pilot",
                "Step": i,
                "Speed": f"{info.get('velocity', 0):.1f} km/h"
            })
            
            # å¦‚æœæ’è½¦æˆ–è·‘å®Œï¼Œé‡ç½®ç¯å¢ƒ
            if done or truncated:
                episode_count += 1
                print(f"Episode {episode_count} ç»“æŸ (Global Step {i})ï¼Œé‡ç½®ç¯å¢ƒ...")
                obs, info = env.reset()
                prev_action = None
                
    except KeyboardInterrupt:
        print("æ¼”ç¤ºå·²åœæ­¢ã€‚")
    finally:
        env.close()

if __name__ == "__main__":
    evaluate()